# Grandes Modelos del Lenguaje
## Large Language Models (LLMs)

[Presentación](../files/Presentación ChatGPT.pdf "ChatGPT")

## 1. Introducción

Los **Large Language Models (LLMs)** son modelos de inteligencia artificial diseñados para **comprender, generar y manipular lenguaje natural**. Constituyen uno de los avances más relevantes de la inteligencia artificial moderna y son la base de herramientas como **ChatGPT**.

Estos modelos no “razonan” en el sentido humano clásico, sino que **aprenden patrones estadísticos del lenguaje** a partir de grandes volúmenes de datos textuales, permitiendo generar respuestas coherentes, contextualizadas y sorprendentemente útiles en múltiples dominios.

---

## 2. Inteligencia artificial y lenguaje

La **inteligencia** puede entenderse como la capacidad de aprender, razonar, tomar decisiones y formarse una representación de la realidad. Desde esta perspectiva, la inteligencia artificial busca **replicar o simular estas capacidades mediante máquinas**.

El nacimiento formal de la IA como disciplina científica se sitúa en **1956**, durante la **Conferencia de Dartmouth**, liderada por **John McCarthy**, donde se planteó que cualquier aspecto de la inteligencia podría describirse con suficiente precisión como para ser simulado por una máquina :contentReference[oaicite:1]{index=1}.

---

## 3. Del razonamiento simbólico al reconocimiento de patrones

Durante décadas, la IA se apoyó en el **razonamiento lógico y simbólico**, con raíces en la lógica formal desarrollada desde **Aristóteles**. Ejemplos emblemáticos de esta etapa son los sistemas expertos o **Deep Blue**, la supercomputadora de IBM que venció a Garry Kaspárov en 1996.

Sin embargo, muchos problemas del mundo real —visión, lenguaje, audición— resultaron difíciles de abordar únicamente mediante reglas explícitas. Esto llevó a un cambio de paradigma hacia el **reconocimiento de patrones**, apoyado en métodos estadísticos y redes neuronales.

---

## 4. Redes neuronales artificiales

Las **redes neuronales artificiales** se inspiran, de forma abstracta, en el funcionamiento del cerebro humano. Permiten modelar funciones complejas a partir de ejemplos, sin necesidad de definir reglas explícitas.

Este enfoque ha sido clave para avances en:
- Visión artificial (conducción autónoma, búsqueda por imágenes)
- Audición (asistentes virtuales)
- Generación de contenido (imágenes, texto, audio)
- Traducción automática y procesamiento del lenguaje natural

---

## 5. Modelos de lenguaje

Un **modelo de lenguaje** es un sistema que asigna probabilidades a secuencias de palabras. En esencia, aprende a responder preguntas como:

> *¿Cuál es la palabra más probable que viene a continuación?*

Este enfoque se basa en:
- Frecuencias y coocurrencias de palabras
- Dependencias contextuales
- Representaciones vectoriales del lenguaje

A medida que aumenta el tamaño del modelo y del corpus de entrenamiento, emergen capacidades cada vez más sofisticadas.

---

## 6. ¿Qué es GPT?

**GPT** significa:
- **G**enerative
- **P**re-trained
- **T**ransformer

Se trata de una familia de modelos de lenguaje desarrollados por **OpenAI**, basados en la arquitectura **Transformer**, que permite procesar texto teniendo en cuenta el contexto completo de una secuencia.

Principales versiones:
- GPT-2 (2019)
- GPT-3 (2020)
- GPT-3.5 (2022)
- GPT-4 / GPT-4o (2023–2024)

ChatGPT se lanzó públicamente el **30 de noviembre de 2022** y supuso la popularización masiva de los LLMs.

---

## 7. ¿Cómo funcionan los LLMs?

Los LLMs funcionan mediante:
1. **Entrenamiento** con grandes corpus textuales.
2. **Aprendizaje estadístico** de patrones del lenguaje.
3. **Predicción secuencial** de tokens (palabras o fragmentos).

Por ejemplo, al generar una frase como:
> “Dos más dos son cuatro”

el modelo no “sabe matemáticas” en sentido estricto, sino que ha aprendido que esa secuencia tiene una alta probabilidad en el lenguaje humano.

---

## 8. Epifenómenos en los LLMs

Un concepto clave es el de **epifenómeno**: comportamientos que **emergen** como consecuencia del entrenamiento, sin haber sido programados explícitamente.

En los LLMs aparecen epifenómenos como:
- Aparente razonamiento lógico
- Teoría de la mente (atribución de creencias)
- Capacidad de explicación adaptada al nivel del interlocutor

Estos comportamientos **no implican comprensión consciente**, sino patrones complejos aprendidos.

---

## 9. Capacidades y limitaciones

### Capacidades
- Generación de texto coherente
- Resumen y explicación de contenidos
- Traducción automática
- Apoyo educativo y creativo
- Interacción en lenguaje natural

### Limitaciones
- No tienen comprensión real
- Pueden cometer errores con alta confianza
- Dependen del contexto y del prompt
- No acceden a la verdad, sino a la probabilidad

---

## 10. Reflexión final

Como afirmó **Arthur C. Clarke**:

> *“Toda tecnología lo suficientemente avanzada es indistinguible de la magia.”*

Comprender cómo funcionan los LLMs permite **desmitificar** herramientas como ChatGPT y utilizarlas de forma **crítica, responsable y eficaz** en contextos educativos, investigadores y profesionales.

Este conocimiento será la base para los siguientes temas del curso.
